Documentation
=====================================

Dataset used
	Harvard dataverse: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/XPCVEI&version=3.0
	~18000 speeches from about 55-60 speakers in .RData format -> reduced to 1000 for faster experiments
	used R to extract only the text of the speech and the author name and reduce other data
Disadvantage of the dataset-a - stop words removed, stemmed words, without sentences!

Stylometry paper - http://scielo.org.mx/scielo.php?script=sci_arttext&pid=S1405-55462018000100047#fn1

stylometric_features.py - used NLTK, spaCy
		NLP-preprocessing
		generating attributes:
					average word length, standard deviation word length
					normalised Named Entities
					normalised Noun number, normalised Verb number, normalised Adjective number
					POS tags entropy
					lexical diversity

stylometric_features.csv
		generated by stylometric_features.py

feature_calculation.log
		log file used during stylometric_features.py executing

classify.py - used sklearn
		classification part using scikit learn, 2 algorithms (SVM (One-VS-One Multi-class classification and One-VS-Rest Multi-class Classification))

classification_calculation.log
		log file used during classify.py executing

speeches.txt
		data in .CSV format generated from .RData by the R script

========================================